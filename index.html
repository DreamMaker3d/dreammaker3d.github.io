<!DOCTYPE html>
<html>

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XB3PR2Y1TQ"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-XB3PR2Y1TQ');
    </script>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>DreamMaker</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css">
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,500,600' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/assets/css/Highlight-Clean.css">
    <link rel="stylesheet" href="/assets/css/styles.css">

    <link rel="apple-touch-icon" sizes="180x180" href="/assets/icon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/assets/icon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/assets/icon/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">

    <meta property="og:site_name" content="DreamFusion: Text-to-3D using 2D Diffusion" />
    <meta property="og:type" content="video.other" />
    <meta property="og:title" content="DreamFusion: Text-to-3D using 2D Diffusion" />
    <meta property="og:description" content="DreamFusion: Text-to-3D using 2D Diffusion, 2022." />
    <meta property="og:url" content="https://dreamfusion3d.github.io/" />
    <meta property="og:image" content="https://dreamfusion3d.github.io/assets/images/dreamfusion_samples.png" />

    <meta property="article:publisher" content="https://dreamfusion3d.github.io/" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="DreamFusion: Text-to-3D using 2D Diffusion" />
    <meta name="twitter:description" content="We combine neural rendering with a multi-modal text-to-2D image diffusion generative model to synthesize diverse 3D objects from text." />
    <meta name="twitter:url" content="https://dreamfusion3d.github.io/" />
    <meta name="twitter:image" content="https://dreamfusion3d.github.io/assets/images/dreamfusion_samples.png" />
    <!-- <meta name="twitter:site" content="" /> -->

    <script src="assets/js/video_comparison.js"></script>
    <script type="module" src="https://unpkg.com/@google/model-viewer@2.0.1/dist/model-viewer.min.js"></script>
</head>

<body>
<!--    <div class="banner">-->
<!--      <video class="video lazy"-->
<!--          poster="https://dreamfusion-cdn.ajayj.com/sept28/banner_1x6_customhue_A.jpg"-->
<!--          autoplay loop playsinline muted>-->
<!--        <source data-src="https://dreamfusion-cdn.ajayj.com/sept28/banner_1x6_customhue_A.mp4" type="video/mp4"></source>-->
<!--      </video>-->
<!--    </div>-->
    <div class="highlight-clean" style="padding-bottom: 10px;">
        <div class="container" style="max-width: 768px;">
            <h1 class="text-center"><b>DreamMaker</b>: Making High-quality Text-to-3D Generation with 3D Consistent Regularization</h1>
        </div>
        <div class="container" style="max-width: 768px;">
            <div class="row authors">
                <div class="col-sm">
                    <h5 class="text-center">Anonymous Author</h5>
                    <h6 class="text-center">Affiliation</h6>
                </div>
            </div>    
        </div>
<!--        <div class="buttons" style="margin-bottom: 8px;">-->
<!--            <a class="btn btn-light" role="button" href="https://arxiv.org/abs/2209.14988">-->
<!--                <svg style="width:24px;height:24px;margin-left:-12px;margin-right:12px" viewBox="0 0 24 24">-->
<!--                    <path fill="currentColor" d="M16 0H8C6.9 0 6 .9 6 2V18C6 19.1 6.9 20 8 20H20C21.1 20 22 19.1 22 18V6L16 0M20 18H8V2H15V7H20V18M4 4V22H20V24H4C2.9 24 2 23.1 2 22V4H4M10 10V12H18V10H10M10 14V16H15V14H10Z"></path>-->
<!--                </svg>Paper-->
<!--            </a>-->
<!--            <a class="btn btn-light disabled border border-dark" aria-disabled="true" role="button" href="#">-->
<!--                <svg style="visibility:hidden;width:0px;height:24px;margin-left:-12px;margin-right:12px" width="0px" height="24px" viewBox="0 0 375 531">-->
<!--                    <polygon stroke="#000000" points="0.5,0.866 459.5,265.87 0.5,530.874 "/>-->
<!--                </svg>-->
<!--                Project-->
<!--            </a>-->
<!--            <a class="btn btn-light" role="button" href="/gallery.html">-->
<!--                <svg style="width:24px;height:24px;margin-left:-12px;margin-right:12px" width="24px" height="24px" viewBox="0 0 375 531">-->
<!--                    <polygon stroke="#000000" points="0.5,0.866 459.5,265.87 0.5,530.874 "/>-->
<!--                </svg>-->
<!--                Gallery-->
<!--            </a>-->
<!--        </div>-->
    </div>
    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>Abstract</h2>
                <p>
                    <!-- <strong> -->
                    2D diffusion-based text-to-3D generation models often encounter the Multi-face Janus problem, which arises due to the absence of 3D consistency in multi-view image generation. To address this challenge, we propose a novel text-to-3D generation framework called DreamMaker. Our approach incorporates 3D geometry consistent regularizations to enhance multi-view consistency and improve the overall quality of 3D generation. The DreamMaker pipeline incorporates a multi-view image generation model and a large text-to-image model, ensuring both 3D consistent and semantically accurate generation. Additionally, we introduce a refinement module that leverages improved 3D scene parameterization and an adaptive camera view sampling strategy to extract high-resolution meshes and textures. Experimental evaluations demonstrate that DreamMaker achieves impressive results. Importantly, it significantly mitigates the occurrence of the Janus problem by approximately 60%. Comparative studies also indicate that DreamMaker outperforms state-of-the-art approaches such as DreamFusion, Magic3D, and SJC, as it garners more user preferences.                    <!-- </strong> -->
                </p>
            </div>
        </div>
    </div>



    <div class="container" style="max-width: 768px;">
        <div style="text-align: center;">
            <img src="assets/images/architecture.png" style="width: 100%;">
        </div>
    </div>

    </div>
    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>Comparison with state-of-the-art models</h2>
            </div>
        </div>
    </div>
        <div class="container" style="max-width: 768px;">
            <div class="row">
                <div class="col-md-12">
                    <p>
                        Although Magic3D and
                        ProlificDreamer are able to generate high-quality objects in
                        some cases, multi-view inconsistency still occurs in many
                        other cases. For example, in Magic3D, wheels of the vehicle
                        in the first case have inconsistent directions and airplane in
                        the second case has multi-heads. Our DreamMaker further
                        introduces 3D consistency to avoid the Janus problem and
                        can still produce high-resolution meshes and high-quality
                        textures. We use the threestudio implementation for all the baselines.                     </p>
                </div>
            </div>
        </div>

<div class="container" style="max-width: 768px;">

<div class="row">
    <!-- <div class="column-3">
        <p>Magic3D-IF-SD</p>
    </div>
    <div class="column-3">
                <p>ProlificDreamer</p>
    </div>
    <div class="column-3">
                <p>Ours</p>
    </div>
</div> -->


        <!-- <div class="row" style="margin-bottom: 0px;">
            <div class="col-xs-4 compare-title  compare-title-sm">
                <p>Magic3D-IF-SD</p>
            </div>
            <div class="col-xs-4 compare-title">
                <p>ProlificDreamer</p>
            </div>
            <div class="col-xs-4 compare-title">
                <p>Ours</p>
            </div>
        </div> -->

</div>
<div class="container" style="max-width: 768px;">
    
        <div style="text-align: center;">
            <p class="compare-caption" style="display: inline-block;">
                Magic3D-IF-SD &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp ProlificDreamer &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp Ours &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp</p>
        </div>


    <div class="row captioned_videos">
        <video class="video lazy" loop playsinline autoplay muted style="width: 100%">
            <source
                src="assets/video/Beautifully_designed_hyper-realistic_futuristic_electric_vehicle_for_elderly_people_highest_poly_count_highest_contrast_highest_detail_highest_quality_UHD.mp4"
                type="video/mp4">
            </source>
        </video>
    </div>
    <div style="text-align: center;">
        <p class="compare-caption" style="display: inline-block;">
            Beautifully designed hyper-realistic futuristic electric vehicle for elderly people highest poly count highest contrast highest detail highest quality UHD
        </p>
    </div>
    <div class="row captioned_videos">
        <video class="video lazy" loop playsinline autoplay muted style="width: 100%">
            <source
                src="assets/video/Beautifully_designed_hyper-realistic_psychedelic_bee-concept_futuristic_fighter_jet_aircraft_highest_contrast_highest_poly_count_highest_detail_highest_quality_UHD.mp4"
                type="video/mp4">
            </source>
        </video>
    </div>
    <div style="text-align: center;">
        <p class="compare-caption" style="display: inline-block;">
            Beautifully designed hyper-realistic psychedelic bee-concept futuristic fighter jet aircraft highest contrast highest poly count highest detail highest quality UHD
        </p>
    </div>
    <div class="row captioned_videos">
        <video class="video lazy" loop playsinline autoplay muted style="width: 100%">
            <source src="assets/video/a_asian_Santa_Claus.mp4" type="video/mp4"> </source>
        </video>
    </div>
        <div style="text-align: center;">
            <p class="compare-caption" style="display: inline-block;">an Asian Santa Claus</p>
        </div>
    <div class="row captioned_videos">
        <video class="video lazy" loop playsinline autoplay muted style="width: 100%">
            <source src="assets/video/a_metal_bunny_sitting_on_top_of_a_stack_of_chocolate_cookie.mp4" type="video/mp4">
            </source>
        </video>
    </div>
    <div style="text-align: center;">
        <p class="compare-caption" style="display: inline-block;">a metal bunny sitting on top of a stack of chocolate cookie</p>
    </div>


</div>




    </div>
    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>More ablation studies</h2>
                                <p>
                We provide additional ablation studies that
                could not be included in the main body of the paper. These
                studies examine various aspects of our model, including: 1)
                the impact of using different initial images and random seeds
                for initialization, 2) the analysis of the effects with and with-
                out Alpha Entropy Regulation, and Smoothness, 3) the effects of utilizing Zero-1-to-3 during the refinement stage.
                                </p>
                <h2>Random Initialization</h2>
                <p>
                    We assess the impact of using different seeds and initialization images. Our findings indicate that our
                    method is not notably affected by the choice of random initialization. In contrast, DreamFusion and
                    Magic3D heavily relies on the selection of random seeds in achieving high-quality results and avoiding
                    the multi-face Janus problem.<!-- </strong> -->
                </p>
            </div>
        </div>
    </div>
    <div class="container" style="max-width: 768px;">
        <div style="text-align: center;">
            <img src="assets/images/init.png" style="width: 100%;">
        </div>
    </div>
    
    
    </div>
    <!-- <hr class="divider" /> -->
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>Smooth Regulation</h2>
                <p>
                    We conduct an evaluation of the impact of the smoothness loss on our coarse-stage results. Our findings
                    suggest that applying smoothness regulation can enhance the quality of textures. Simultaneously, it has
                    a modest beneficial effect on the quality of the mesh, as visualized via the surface normal
                    maps.<!-- </strong> -->
                </p>
            </div>
        </div>
    </div>
    <div class="container" style="max-width: 768px;">
        <div style="text-align: center;">
            <img src="assets/images/smooth.png" style="width: 100%;">
        </div>
    </div>
    
    
    </div>
    <!-- <hr class="divider" /> -->
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>Entropy Loss</h2>
                <p>
                    We incorporate an additional entropy loss into our model, which aims to address floats and blurs in the
                    background that could enhance the mesh extraction process. We present a comparison of the results
                    obtained when training with and without the implementation of Entropy Loss. The use of entropy loss
                    effectively eliminates the floaters and blurs in the background, leading to clearer and more detailed
                    imagery.<!-- </strong> -->
                </p>
            </div>
        </div>
    </div>
    <div class="container" style="max-width: 768px;">
        <div style="text-align: center;">
            <img src="assets/images/entropy.png" style="width: 100%;">
        </div>
    </div>

    
    
    </div>
    <!-- <hr class="divider" /> -->
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>Zero-1-to-3 in the Refinement Stage</h2>
                <p>
                We evaluate the effects of utilizing Zero-1-to-3 for surface normal regulation during the refinement stage. Similar to
                our approach in the coarse stage, we feed the surface normal rendering into Zero-1-to-3, while continuing to use
                Stable-Diffusion for RGB SDS loss. Utilizing only
                Stable-Diffusion to compute SDS losses for both surface normal and RGB texture renderings allows our model to generate
                more detailed mesh surfaces. This outcome is attributable to Zero-1-to-3's limitation in only generating low-resolution
                images and providing weak regulation at low resolutions, which renders it unsuitable for the refinement stage that
                necessitates more detailed textures and mesh surfaces.
                </p>
            </div>
        </div>
    </div>
    <div class="container" style="max-width: 768px;">
        <div style="text-align: center;">
            <img src="assets/images/zero123.png" style="width: 100%;">
        </div>
    </div>



    </div>
    <!-- <hr class="divider" /> -->
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>PBR Material Modeling</h2>
                <p>
                In addition to our previous experiments, we also investigate the use of the Physically-Based Rendering (PBR) material
                modeling method during our refinement stage. This method involves
                decomposing the texture into three components of the material model: the diffuse term, the roughness and metallic term,
                and the normal variation term. The PBR material modeling approach can be beneficial for simulation applications.
                </p>
            </div>
        </div>
    </div>
    <div class="container" style="max-width: 768px;">
        <div style="text-align: center;">
            <img src="assets/images/pbr.png" style="width: 100%;">
        </div>
    </div>


   <!-- <div class="container" style="max-width: 768px;">-->
<!--        <div class="row captioned_videos">-->
<!--            <div class="col-md-12">-->
<!--                &lt;!&ndash; Large format devices &ndash;&gt;-->
<!--                <video class="video lazy d-none d-xs-none d-sm-block" autoplay loop playsinline muted poster="https://dreamfusion-cdn.ajayj.com/sept28/wipe_opposite_6x4_smoothstep.jpg">-->
<!--                    <source data-src="https://dreamfusion-cdn.ajayj.com/sept28/wipe_opposite_6x4_smoothstep.mp4" type="video/mp4"></source>-->
<!--                </video>-->
<!--                &lt;!&ndash; Small format devices &ndash;&gt;-->
<!--                <video class="video lazy d-xs-block d-sm-none" autoplay loop playsinline muted poster="https://dreamfusion-cdn.ajayj.com/sept28/shaded_3x3_smoothstep.jpg">-->
<!--                    <source data-src="https://dreamfusion-cdn.ajayj.com/sept28/shaded_3x3_smoothstep.mp4" type="video/mp4"></source>-->
<!--                </video>-->
<!--                <h6 class="caption">Given a caption, DreamFusion generates relightable 3D objects with high-fidelity appearance, depth, and normals. Objects are represented as a Neural Radiance Field and leverage a pretrained text-to-image diffusion prior such as Imagen.</h6>-->
<!--            </div>-->
<!--        </div>-->
<!--    </div> -->
<!--    <hr class="divider" />-->
<!--    <div class="container" style="max-width: 768px;">-->
<!--        <div class="row">-->
<!--            <div class="col-md-12">-->
<!--                <h2>Generate 3D from text yourself!</h2>-->
<!--            </div>-->
<!--        </div>-->
<!--        <div class="row compositional captioned_videos">-->
<!--            <div class="col-sm-8 text">-->
<!--                <p class="selectable left" id="compositional_tags_depth_0"></p>-->
<!--            </div>-->
<!--            <div class="col-sm-4 my-auto">-->
<!--                <div class="video-compare-container">-->
<!--                    <video id="compositionalVideo" class="video" autoplay loop playsinline muted>-->
<!--                        <div class="screen" id="compositionalScreen"></div>-->
<!--                        <source id="compositionalVideoSrc" src="https://dreamfusion-cdn.ajayj.com/journey_sept28/cropped/full_continuous/a_DSLR_photo_of_a_squirrel___rgbdn_hq_15000.mp4" type="video/mp4">-->
<!--                    </video>-->
<!--                    &lt;!&ndash; <video onplay="resizeAndPlay(this)" style="height: 0px;" id="compositionalVideo" class="video lazy" autoplay loop playsinline muted>-->
<!--                        <source id="compositionalVideoSrc" data-src="https://dreamfusion-cdn.ajayj.com/journey_sept28/full/a_DSLR_photo_of_a_squirrel___rgbdn_hq_15000.mp4" type="video/mp4">-->
<!--                    </video> &ndash;&gt;-->
<!--                    &lt;!&ndash; <canvas height="752" class="videoMerge" id="compositionalVideoMerge" width="1002"></canvas> &ndash;&gt;-->
<!--                </div>-->
<!--                &lt;!&ndash; <h6 class="caption" id="compositionalCaption">a DSLR photo of a squirrel</h6> &ndash;&gt;-->
<!--            </div>-->
<!--        </div>-->
<!--    </div>-->
<!--    <hr class="divider" />-->
<!--    <div class="container" style="max-width: 768px;">-->
<!--        <div class="row">-->
<!--            <div class="col-sm-8">-->
<!--                <h2>Example generated objects</h2>-->
<!--                <p>DreamFusion generates objects and scenes from diverse captions. <a href="/gallery.html">Search through hundreds of generated assets in our full gallery.</a></p>-->
<!--            </div>-->
<!--            <div class="col-sm-4 my-auto">-->
<!--                <a href="/gallery.html" class="btn btn-primary btn-lg btn-search"><svg xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" viewbox="0 0 600 550">-->
<!--                    <path fill="none" stroke="#fff" stroke-width="36" stroke-linecap="round" d="m280,278a153,153 0 1,0-2,2l170,170m-91-117 110,110-26,26-110-110"/>-->
<!--                    </svg>Search assets-->
<!--                </a>-->
<!--            </div>-->
<!--        </div>-->
<!--        <div class="row captioned_videos" id="randomVideos">-->
<!--            &lt;!&ndash; <div class="col-4">-->
<!--                <div class="video-compare-container" style="width: 100%">-->
<!--                    <video class="video lazy" id="ex1" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">-->
<!--                        <source data-src="https://dreamfusion-cdn.ajayj.com/gallery/a_teddy_bear_pushing_a_shopping_cart_full_of_fruits_and_vegetables_rgbdn_hq_15000.mp4" type="video/mp4"></source>-->
<!--                    </video>-->
<!--                    <canvas height="752" class="videoMerge" id="ex1Merge" width="1002"></canvas>-->
<!--                </div>-->
<!--                <h6 class="caption">A teddy bear pushing a shopping cart full of fruits and vegetables.</h6>-->
<!--            </div>-->
<!--            <div class="col-4">-->
<!--                <div class="video-compare-container" style="width: 100%">-->
<!--                    <video class="video lazy" id="ex2" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">-->
<!--                        <source data-src="https://dreamfusion-cdn.ajayj.com/gallery/a_sliced_loaf_of_fresh_bread_rgbdn_hq_15000.mp4" type="video/mp4"></source>-->
<!--                    </video>-->
<!--                    <canvas height="752" class="videoMerge" id="ex2Merge" width="1002"></canvas>-->
<!--                </div>-->
<!--                <h6 class="caption">a sliced loaf of fresh bread.</h6>-->
<!--            </div>-->
<!--            <div class="col-4">-->
<!--                <div class="video-compare-container" style="width: 100%">-->
<!--                    <video class="video lazy" id="ex3" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">-->
<!--                        <source data-src="https://dreamfusion-cdn.ajayj.com/gallery/a_zoomed_out_DSLR_photo_of_Sydney_opera_house,_aerial_view_rgbdn_hq_15000.mp4" type="video/mp4"></source>-->
<!--                    </video>-->
<!--                    <canvas height="752" class="videoMerge" id="ex3Merge" width="1002"></canvas>-->
<!--                </div>-->
<!--                <h6 class="caption">a zoomed out DSLR photo of Sydney opera house, aerial view.</h6>-->
<!--            </div> &ndash;&gt;-->
<!--        </div>-->
<!--    </div>-->
<!--    <hr class="divider" />-->
<!--    <div class="container" style="max-width: 768px;">-->
<!--        <div class="row">-->
<!--            <div class="col-md-12">-->
<!--                <h2>Composing objects into a scene</h2>-->
<!--                &lt;!&ndash; <p>Our generated NeRF models can be exported to meshes using the marching cubes algorithm for easy integration into 3D renderers or modeling software.</p> &ndash;&gt;-->
<!--                <video class="video lazy" autoplay loop playsinline controls muted poster="https://dreamfusion-cdn.ajayj.com/carouselx24_128tall.jpg">-->
<!--                    <source src="https://dreamfusion-cdn.ajayj.com/carouselx24_128tall.mp4" type="video/mp4"></source>-->
<!--                </video>-->
<!--            </div>-->
<!--        </div>-->
<!--    </div>-->
   <hr class="divider" />
    <div class="container meshes" id="meshContainer" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>Mesh exports</h2>
                <p>We can extract mesh from our fine stage result.</p>
            </div>
        </div>
    </div>
    <hr class="divider" />
<!--    <div class="container" style="max-width: 768px;">-->
<!--        <div class="row">-->
<!--            <div class="col-md-12">-->
<!--                <h2>How does DreamFusion work?</h2>-->
<!--                <p>Given a caption, DreamFusion uses a text-to-image generative model called Imagen to optimize a 3D scene. We propose <strong>Score Distillation Sampling (SDS)</strong>, a way to generate samples from a diffusion model by optimizing a loss function. SDS allows us to optimize samples in an arbitrary parameter space, such as a 3D space, as long as we can map back to images differentiably. We use a 3D scene parameterization similar to Neural Radiance Fields, or NeRFs, to define this differentiable mapping. SDS alone produces reasonable scene appearance, but DreamFusion adds additional regularizers and optimization strategies to improve geometry. The resulting trained NeRFs are coherent, with high-quality normals, surface geometry and depth, and are relightable with a Lambertian shading model.</p>-->
<!--            </div>-->
<!--        </div>-->
<!--        <div class="row">-->
<!--            <div class="col-md-12">-->
<!--                <video class="video lazy" controls muted poster="https://dreamfusion-cdn.ajayj.com/dreamfusion_overview.jpg">-->
<!--                    <source data-src="https://dreamfusion-cdn.ajayj.com/dreamfusion_overview.mp4" type="video/mp4"></source>-->
<!--                </video>-->
<!--            </div>-->
<!--        </div>-->
<!--    </div>-->
<!--    <hr class="divider" />-->
<!--    <div class="container" style="max-width: 768px;">-->
<!--        <div class="row">-->
<!--            <div class="col-md-12">-->
<!--                <h2>Citation</h2>-->
<!--                <code>-->
<!--                    @article{poole2022dreamfusion,<br>-->
<!--                    &nbsp; author = {Poole, Ben and Jain, Ajay and Barron, Jonathan T. and Mildenhall, Ben},<br>-->
<!--                    &nbsp; title  = {DreamFusion: Text-to-3D using 2D Diffusion},<br>-->
<!--                    &nbsp; journal = {arXiv},<br>-->
<!--                    &nbsp; year   = {2022},<br>-->
<!--                }</code>-->
<!--            </div>-->
<!--        </div>-->
<!--    </div>-->
<!--    <script src="https://polyfill.io/v3/polyfill.js?features=IntersectionObserver"></script>-->
<!--    <script src="/assets/js/yall.js"></script>-->
<!--    <script>-->
<!--        yall(-->
<!--            {-->
<!--                observeChanges: true-->
<!--            }-->
<!--        );-->
<!--    </script>-->
    <script src="/assets/js/scripts.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/js/bootstrap.bundle.min.js"></script>
    <script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd002feec.js"></script>


    <div class="container meshes" id="meshContainer2" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>Image to 3D</h2>
                <p>Generate 3D meshes from the given poster image</p>
            </div>
        </div>
    </div>
    <hr class="divider" />
    <script src="/assets/js/scripts2.js"></script>
<!--    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>-->
<!--    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/js/bootstrap.bundle.min.js"></script>-->
<!--    <script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd002feec.js"></script>-->
    <!-- Import the component -->
    <div class="container" style="max-width: 768px;">
            <div class="text-center">Template from <a href="https://dreamfusion3d.github.io/">https://dreamfusion3d.github.io/</a></div>
    </div>
</body>

</html>
